{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비 → 딥러닝 네트워크 설계 → 학습 → 테스트(평가)\n",
    "\n",
    "데이터셋 참고 자료\n",
    " https://tykimos.github.io/2017/03/25/Dataset_and_Fit_Talk/ <br>\n",
    "케라스 이야기\n",
    "https://tykimos.github.io/2017/01/27/Keras_Talk/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 사진 찍기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "teachable machine 사이트에서 쉽게 데이터 만들수 있다.\n",
    "https://teachablemachine.withgoogle.com/\n",
    "\n",
    "여러 각도에서 찍어보세요.\n",
    "여러 크기로 찍어보세요.\n",
    "좋은 데이터를 활용하면 좋은 결과를 얻을수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.디렉토리만들기\n",
    "\n",
    "### 가위,바위,보 이미지 각각을 저장할 폴더 3개를 만들자\n",
    "\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/scissor <br>\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/rock    <br>\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/paper   <br>\n",
    "\n",
    "\n",
    "\n",
    "-p 옵션을 주어 생성하게 되면 자동으로 중간 단계의 디렉토리를 생성하면서 그 하위 디렉토리를 생성하게된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.이미지 크기 조절하기(28x28픽셀)\n",
    "함수를 작성하고 안에 for문으로 가위,바위,보 데이터의 사이즈조절 코드를 작성하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper_2000/scissor\n",
      "scissor 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper_2000/rock\n",
      "rock 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper_2000/paper\n",
      "paper 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, glob\n",
    "from PIL import Image  #PIL패키지에서 Image모듈가져옴  pillow =PIL : Python Imaging Library  \n",
    "\n",
    "#가위바위보 리스트\n",
    "list =('scissor','rock','paper')\n",
    "\n",
    "# 이미지 28,28로 변경하는 함수\n",
    "def change_img(str):\n",
    "    target_size=(28,28) \n",
    "    for str_srp in list:\n",
    "        image_dir_path = os.getenv(\"HOME\")+\"/aiffel/rock_scissor_paper_2000/\"+str_srp \n",
    "        print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "        images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "        #print(type(images))\n",
    "        # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "        #target_size=(28,28)\n",
    "        for img in images:\n",
    "            old_img=Image.open(img)\n",
    "            new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "            new_img.save(img,\"JPEG\")\n",
    "        print(str_srp + \" 이미지 resize 완료!\")\n",
    "\n",
    "#함수 호출        \n",
    "change_img(list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가위,바위,보 각 3개의 디렉토리의 이미지 변경(28x28)을 한 함수로 정의하였다.\n",
    "\n",
    "import os   -> os 모듈을 가져온다.\n",
    "import glob -> glob는 파일들의 리스트를 뽑을 때 사용하는데, 파일의 경로명을 이용해서 접근할수 있다.\n",
    "                참고 https://wikidocs.net/3746\n",
    "\n",
    "from PIL import Image -> PIL패키지에서 Image모듈가져옴  \n",
    "                      -> pillow = PIL : Python Imaging Library \n",
    "\n",
    "\n",
    "\n",
    "image_dir_path : 이미지(가위,바위,보)경로 변수\n",
    "\n",
    "glob.glob(\"경로\"+ \"/*.jpg\") : 경로에 존재하는 jpg확장자를 리스트로 반환\n",
    "\n",
    "old_img = Image.open(이미지명.확장자) : 이미지 불러와서 old_img변수에 저장\n",
    "\n",
    "old_img.resize(target_size,Image.ANTIALIAS) : 사이즈 재설정<br>\n",
    ": resize(인자1,인자2) target_size만큼 이미지크기 조절<br>\n",
    ": Image.ANTIALIAS 좀 더 좋은 품질의 이미지를 저장(?)\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.트레이닝 데이터 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 8799 입니다.\n",
      "x_train shape: (9000, 28, 28, 3)\n",
      "y_train shape: (9000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os, glob\n",
    "from PIL import Image \n",
    "import numpy as np \n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=9000   # 총 이미지 개수\n",
    "    img_size=28   #이미지 픽셀크기(28x28)\n",
    "    color=3   # RGB 3개\n",
    "    \n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    #imgs 6000*28*28*3 형태의 차원행렬? , 값들은 0으로 저장되어 있다.\n",
    "    \n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/rock_scissor_paper_3000\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "# x_train = imgs  ,labels = y_train\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy는 과학 계산을 위한 라이브러리로서 다차원 배열을 처리하는데 필요한 여러 유용한 기능을 제공하고 있다. <br>\n",
    "공학 프로그램의 대표주자인 매틀랩(MATLAB)과 상당히 유사한 파이썬+numpy를 활용하면 행렬 계산을 하는데 유용하게 사용할 수 있다.<br>\n",
    "numpy를 np로 줄여서 표현한다.\n",
    "\n",
    "\n",
    "#### import numpy as np  : numpy의 패키지를 코드에서 호출할때 np로 부른다 \n",
    "\n",
    "#### np.zeros(shape, dtype, order)  참조 https://firework-ham.tistory.com/33\n",
    "np.zeros( 6000 * 28 * 28 * 3, dtype=np.int8) : 28x28x3개 원소를 갖는 zero vector 생성<br>\n",
    ".reshape(6000,28,28,3) : zero vector를 6000x28x28x3 형식으로 재설정한다.<br>\n",
    "(데이터갯수, 이미지 크기 x, 이미지 크기 y, 채널수) 채널수1=흑백 채널수=3(RGB)\n",
    "\n",
    "\n",
    "glob.glob : 경로에 존재하는 파일들을 리스트로 반환<br>\n",
    "glob.iglob : 경로에 존재하는 파일들을 이터레이터로 반환<br>\n",
    "glob 참조 https://docs.python.org/ko/3/library/glob.html\n",
    "\n",
    "numpy의 자료형 https://eunguru.tistory.com/216\n",
    "\n",
    "\n",
    "print(type(x_train)) 출력 <class 'numpy.ndarray'> <br>\n",
    "print(type(y_train)) 출력 <class 'numpy.ndarray'> <br>\n",
    "\n",
    "x_train_norm = x_train/255.0  <br>\n",
    "인공지능 모델을 훈련 및 사용할때, 일반적으로 입력은 0에서 1 사이의 값으로 정규화 시키는것이 좋다. 이미지나 MNIST 데이터는 각 픽셀의 값이 0~255 사이 범위에 있으므로 데이터들을 255.0으로 나누워주자.최소값이 0, 최대값이 1이다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Matplotlib를 활용하여 데어터값 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[900])  # x_train[900]의 이미지표현\n",
    "print('라벨: ', y_train[900])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib은 파이썬에서 매트랩과 유사한 그래프 표시를 가능케 하는 라이브러리다. 데이터를 차트나 플롯(Plot)으로 그려주는 라이브러리 패키지로서 가장 많이 사용되는 데이타 시각화(Data Visualization) 패키지\n",
    "\n",
    "참고 http://pythonstudy.xyz/python/article/407-Matplotlib-%EC%B0%A8%ED%8A%B8-%ED%94%8C%EB%A1%AF-%EA%B7%B8%EB%A6%AC%EA%B8%B0\n",
    "\n",
    "pyplot은 Matplotlib에서 지원하는 모듈\n",
    "pyplo의 인터페이스는 겉으로는 드러나지 않으면서 자동으로 figure와 axes를 생성한다는데 뭔지 모르겠다 /참고 https://wikidocs.net/4763\n",
    "\n",
    "plt.imshow() 참조 https://steemit.com/kr-dev/@dj-on-steem/matplotlib-08-plot-main-imshow\n",
    "\n",
    "\n",
    "print('라벨: ', y_train[900])  : 라벨 0이면 가위, 1이면 바위, 2이면 보"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                51232     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 90,051\n",
      "Trainable params: 90,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_channel_1=64\n",
    "n_channel_2=64\n",
    "n_dense=32 # 8로 지정했을때 정확도가 올라가지 않음\n",
    "n_train_epoch=35\n",
    "\n",
    "model_rock_scissor_paper=keras.models.Sequential()\n",
    "model_rock_scissor_paper.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model_rock_scissor_paper.add(keras.layers.MaxPool2D(2,2))\n",
    "model_rock_scissor_paper.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model_rock_scissor_paper.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model_rock_scissor_paper.add(keras.layers.Flatten())\n",
    "model_rock_scissor_paper.add(keras.layers.Dense(n_dense, activation='relu')) # 분류기 알고리즘을 얼마나 복잡하게 할것인가?\n",
    "model_rock_scissor_paper.add(keras.layers.Dense(3, activation='softmax')) # class수가 3개이므로 3개\n",
    "\n",
    "\n",
    "model_rock_scissor_paper.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 학습시키기(트레이닝세트를 활용하여)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "9000/9000 [==============================] - 2s 257us/sample - loss: 1.7771 - acc: 0.5766\n",
      "Epoch 2/35\n",
      "9000/9000 [==============================] - 2s 248us/sample - loss: 0.5243 - acc: 0.7702\n",
      "Epoch 3/35\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.3786 - acc: 0.8512\n",
      "Epoch 4/35\n",
      "9000/9000 [==============================] - 2s 245us/sample - loss: 0.2915 - acc: 0.8861\n",
      "Epoch 5/35\n",
      "9000/9000 [==============================] - 2s 245us/sample - loss: 0.2228 - acc: 0.9171\n",
      "Epoch 6/35\n",
      "9000/9000 [==============================] - 2s 248us/sample - loss: 0.2057 - acc: 0.9206\n",
      "Epoch 7/35\n",
      "9000/9000 [==============================] - 2s 245us/sample - loss: 0.1530 - acc: 0.9411\n",
      "Epoch 8/35\n",
      "9000/9000 [==============================] - 2s 246us/sample - loss: 0.1294 - acc: 0.9526\n",
      "Epoch 9/35\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.1259 - acc: 0.9553\n",
      "Epoch 10/35\n",
      "9000/9000 [==============================] - 2s 250us/sample - loss: 0.1244 - acc: 0.9558\n",
      "Epoch 11/35\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.0682 - acc: 0.9758\n",
      "Epoch 12/35\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.0562 - acc: 0.9802\n",
      "Epoch 13/35\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.0894 - acc: 0.9677\n",
      "Epoch 14/35\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.1028 - acc: 0.9667\n",
      "Epoch 15/35\n",
      "9000/9000 [==============================] - 2s 246us/sample - loss: 0.1148 - acc: 0.9647\n",
      "Epoch 16/35\n",
      "9000/9000 [==============================] - 2s 250us/sample - loss: 0.0424 - acc: 0.9867\n",
      "Epoch 17/35\n",
      "9000/9000 [==============================] - 2s 248us/sample - loss: 0.0448 - acc: 0.9831\n",
      "Epoch 18/35\n",
      "9000/9000 [==============================] - 2s 248us/sample - loss: 0.0604 - acc: 0.9789\n",
      "Epoch 19/35\n",
      "9000/9000 [==============================] - 2s 248us/sample - loss: 0.0811 - acc: 0.9758\n",
      "Epoch 20/35\n",
      "9000/9000 [==============================] - 2s 248us/sample - loss: 0.0656 - acc: 0.9791\n",
      "Epoch 21/35\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.0221 - acc: 0.9928\n",
      "Epoch 22/35\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.0197 - acc: 0.9934\n",
      "Epoch 23/35\n",
      "9000/9000 [==============================] - 2s 246us/sample - loss: 0.0065 - acc: 0.9978\n",
      "Epoch 24/35\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.0820 - acc: 0.9732\n",
      "Epoch 25/35\n",
      "9000/9000 [==============================] - 2s 248us/sample - loss: 0.0703 - acc: 0.9799\n",
      "Epoch 26/35\n",
      "9000/9000 [==============================] - 2s 256us/sample - loss: 0.0305 - acc: 0.9904\n",
      "Epoch 27/35\n",
      "9000/9000 [==============================] - 2s 251us/sample - loss: 0.0298 - acc: 0.9898\n",
      "Epoch 28/35\n",
      "9000/9000 [==============================] - 2s 260us/sample - loss: 0.0502 - acc: 0.9866\n",
      "Epoch 29/35\n",
      "9000/9000 [==============================] - 2s 252us/sample - loss: 0.0479 - acc: 0.9859\n",
      "Epoch 30/35\n",
      "9000/9000 [==============================] - 2s 252us/sample - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 31/35\n",
      "9000/9000 [==============================] - 2s 251us/sample - loss: 0.0261 - acc: 0.9931\n",
      "Epoch 32/35\n",
      "9000/9000 [==============================] - 2s 250us/sample - loss: 0.0915 - acc: 0.9743\n",
      "Epoch 33/35\n",
      "9000/9000 [==============================] - 2s 249us/sample - loss: 0.0184 - acc: 0.9940\n",
      "Epoch 34/35\n",
      "9000/9000 [==============================] - 2s 250us/sample - loss: 0.0038 - acc: 0.9991\n",
      "Epoch 35/35\n",
      "9000/9000 [==============================] - 2s 250us/sample - loss: 0.0064 - acc: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f749ed42ed0>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rock_scissor_paper.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "#optimizer='adam' 최적화는 adam방식, 손실함수는 sparse_categorical_crossentropy 사용\n",
    "\n",
    "\n",
    "#모델 훈련\n",
    "model_rock_scissor_paper.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile()모델 학습과정 설정하기 <br>\n",
    "model.fit()    모델 학습시키기\n",
    "\n",
    "optimizer='adam' 최적화는 adam방식, 손실함수는 sparse_categorical_crossentropy 사용\n",
    "\n",
    "\n",
    "<br>\n",
    "sparse_categorical_crossentropy 다중 분류 손실 함수 https://hororolol.tistory.com/375\n",
    "\n",
    "\n",
    "compile()시 파라미터로 준 metrics라는 것은 훈련할 때 보여주는 공간 뜻한다.즉, 훈련을 모니터링하기 위한 지표를 선택하는 것이고 이를 'accuracy'로 지정함\n",
    "1.222 -> 1 이와 같이 1.XXX값은 1로 분류해버리는 분류모델 같은 경우에 사용하는 지표가 'accuracy'이다. <br>\n",
    "소수점을 사용하는 회귀 모델 같은 경우는 accuracy를 사용할 수 없습니다.\n",
    "참조https://ebbnflow.tistory.com/122\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "x_train 트레이닝 이미지들<br>\n",
    "y_train 트레이닝 라벨 0~2의 값들<br>\n",
    "n_train_epoch  에포크 - 훈련셋을 몇 번 반복해서 학습할 것인가를 정하는 것<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.테스팅 데이터 만들기\n",
    "\n",
    "<br>트레이닝 데이터 만드는방법과 동일하다 데이터의 양과 데이터 가 틀림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "import numpy as np #추가\n",
    "\n",
    "\n",
    "def load_test_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300  \n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/rock_scissor_paper_test\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.8873891500096458 \n",
      "test_accuracy: 0.8233333230018616\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model_rock_scissor_paper.evaluate(x_test, y_test, verbose=3)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "데이터를 아래와 같이 준비하고 학습을 해보왔다.  \n",
    "트레이닝 데이터 :300장, 3000장 6000장 9000장  \n",
    "테스트 데이터 :3개의 300장 (팀원 3명에 대한 이미지)  \n",
    "\n",
    "트레이닝 데이터가 300장 인 경우 정확도 30% 미만, 3000장인 경우 40%~60%, 6000장은 50~65% 의 결과가 나왔다. 그런데 9000장을 돌리면 더 높은 정확도나 나올줄 알았는데 6000장보다 낮거나 비슷한정도로 나왔다. 그래서 에포크의 수치를 높여보니 높은수치 wj가 나왔다.(오버피팅때문에 에포크를 너무 낮춰도 안되는것같다.) 즉 이미지양이 많을수록 그만큼 에포크 수치를 높아야 훈련학습을 잘하는것 같다.\n",
    "또한 트레이닝 이미지를 수집할때 선별적으로 데이터를 수집해야되는것 같다. 아이펠 교육생분들의 여러 가위,바위,보 이미지가 있었지만 그중에서 뒷 배경때문에 이것이 손인지 구분이 안되는 경우가 있었고, 너무 뒤에서 찍어서 가위인지 바위인지 알수 없었던 이미지들도 있었다. 그래서 이러한 애매호모한 이미지들을 제거하고 훈련을 해보니 조금더 높은 정확도수치를 얻을수 있었다. 이런방법은 말 그대로 정확도를 올리기 위한 방법이기에 적절하지 않은 방법이라고 생각되지만 이런 저런 방법을 적용하면서 머신러닝에 조금더 이해하게 된것 같다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
