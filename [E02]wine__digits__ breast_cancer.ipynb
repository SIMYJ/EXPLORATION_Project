{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마이크로 평균(Micro-average), 매크로 평균(Macro-average) 이란 무엇인가?\n",
    " https://unlimitedpower.tistory.com/entry/IR-마이크로-평균Micro-average-매크로-평균Macro-average-이란-무엇인가 [오늘도 공장은 돌아간다.]\n",
    "\n",
    "  Macro-average, Micro-average 이 둘의 값은 매우 차이가 나게 되면 특정 반(카테고리)에 데이터가 편중된다.\n",
    "\n",
    "### weighted avg 가중 산술 평균\n",
    "https://ko.wikipedia.org/wiki/%EA%B0%80%EC%A4%91_%EC%82%B0%EC%88%A0_%ED%8F%89%EA%B7%A0\n",
    "\n",
    "  \n",
    "### 분류성능평가지표 - Precision(정밀도), Recall(재현율) and Accuracy(정확도)\n",
    "https://sumniya.tistory.com/26\n",
    "\n",
    "\n",
    "### 다중 클래스에 대한 Confusion Matri한 설명\n",
    "https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826\n",
    "\n",
    "```\n",
    "------------------------------------------------------------------------------------------------------\n",
    "TP, FN, FP, TN의 수치로 계산되는 성능 지표 중 대표적으로 쓰이는 것은 정밀도(Precision), 재현율(Recall, Sensitivity), F1 스코어(f1 score)이라고 한다.\n",
    "\n",
    "\n",
    "```\n",
    "   \n",
    "<span style=\"font-size:125%;\">\n",
    "    Precision(정밀도): 양성에 대하여 거짓,참 여부를 예측할때 진짜로 양성인 경우 <br>    \n",
    "    Recall(재현율)   : 실제값이 양성을 의미하는 것중 예측을 양성이 사실이라고 직접적으로 한 경우<br>    \n",
    "    <br>\n",
    "    F1 스코어(f1 score) : 정밀도와 재현율의 값을 활용한 지표(정밀도값과 재현율값의 조화평균)<br>\n",
    "    accurancy(정확도) : Accuracy는 TP,TF ,FP FT 모든 지표를 활용한 경우<br><br><br>\n",
    "</span>    \n",
    "\n",
    "\n",
    "<span style=\" font: bold 1.7em/2em Georgia ;\">    \n",
    "    \n",
    "$precision  =\\frac{TP(실제양성,양성예측(참))}{{TP(실제양성,양성예측(참))}+{FP(실제음성,양성예측(거짓))}}$  \n",
    "\n",
    "\n",
    "\n",
    "$Recall  =\\frac{TP(실제양성,양성예측(참))}{{TP(실제양성,양성예측(참))}+{FN(실제양성,음성예측(거짓))}}$ \n",
    "<br><br>\n",
    "<font size=5>\n",
    "$f1 score=\\frac{2}{{\\frac{1}{정밀도}}+{\\frac{1}{재현율}}}$<br><br>\n",
    "$accurancy=\\frac{{TP}+{TN}}{TP+TN+FP+FN}$\n",
    "    \n",
    "    \n",
    "</font>\n",
    "</span> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손글씨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 모듈 import하기\n",
    "from sklearn.datasets import load_digits # 사이킷런 토이데이터셋(손글씨)\n",
    "from sklearn.model_selection import train_test_split # 분리를 위한 패키지\n",
    "from sklearn.metrics import classification_report # 정밀도, 재현율, F1 score 제공하는 패키지\n",
    "\n",
    "#데이터 준비\n",
    "digits = load_digits()\n",
    "digits.keys() #digits.key() 어떤 정보들이 담겼을지, keys() 라는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Data 지정하기\n",
    "digits_data = digits.data\n",
    "digits_data.shape # 1797개의 데이터와 64개 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label Data 지정하기\n",
    "digits_label = digits.target\n",
    "#Target Names 출력해 보기\n",
    "digits.target_names # 라벨의 이름을 확인한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "#데이터 Describe 해 보기\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "y_test shape: (360,)\n",
      "y_test shape: [6 0 5 9 2 9 0 4 1 0 1 8 2 5 2 8 1 8 9 1 0 2 0 4 5 3 3 0 0 4 1 4 4 4 6 1 4\n",
      " 0 6 6 0 9 3 6 6 2 0 1 9 6 2 8 9 9 0 2 0 8 4 6 8 5 8 7 8 7 7 4 1 4 5 5 4 6\n",
      " 2 0 1 3 7 5 8 2 4 4 2 5 1 9 3 7 6 3 3 5 6 2 1 0 1 9 4 1 1 3 1 6 9 0 3 7 6\n",
      " 9 3 8 0 8 3 8 8 6 3 7 3 9 0 3 0 9 8 1 2 2 3 6 9 4 0 5 4 2 9 1 0 2 5 0 2 2\n",
      " 7 4 6 9 8 2 6 0 4 4 8 5 0 2 4 6 8 2 3 7 2 9 0 3 5 9 1 6 8 7 5 3 0 4 2 1 3\n",
      " 3 6 0 2 8 4 1 4 7 5 7 6 6 8 1 0 6 8 7 1 1 9 8 5 5 3 6 8 1 2 0 7 5 3 0 8 2\n",
      " 0 4 0 9 4 8 4 7 9 7 3 6 2 5 1 5 9 2 9 9 8 2 1 6 7 1 7 5 7 8 9 5 7 4 3 7 8\n",
      " 8 2 8 9 5 3 2 8 0 4 2 1 0 8 4 1 7 1 4 7 7 1 8 3 8 4 3 5 9 4 4 8 1 8 7 2 3\n",
      " 1 1 1 0 2 8 0 7 4 0 1 0 2 3 7 9 8 5 8 2 2 6 5 0 8 9 8 9 0 0 9 7 4 1 2 6 7\n",
      " 3 7 4 0 2 1 7 2 5 7 2 3 5 7 1 4 1 3 3 8 8 1 0 1 9 3 0]\n"
     ]
    }
   ],
   "source": [
    "#train, test 데이터 분리\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,    # 데이터 feature \n",
    "                                                    digits_label,   # 데이터 label   0~9\n",
    "                                                    test_size=0.2,# 전체 중 20%만 테스트 데이터로 사용하겠다.\n",
    "                                                    random_state=7)\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))\n",
    "\n",
    "print(\"y_test shape: {}\".format(y_test.shape) )\n",
    "print(\"y_test shape: {}\".format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터 1797개에서 1437개의 훈련데이터, 360개의 테스트데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.tree import DecisionTreeClassifier # 의사결정트리 패키지\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForest 모델\n",
    "from sklearn import svm # svm모델\n",
    "from sklearn.linear_model import SGDClassifier #SGD모델\n",
    "from sklearn.linear_model import LogisticRegression #로지스틱 회귀 모델 \n",
    "from sklearn.metrics import classification_report  # 정확도(precision,recall,f1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 34,  3,  1,  0,  1,  1,  0,  0,  2],\n",
       "       [ 0,  0, 33,  2,  0,  0,  1,  1,  2,  1],\n",
       "       [ 0,  1,  0, 31,  0,  0,  0,  0,  1,  1],\n",
       "       [ 0,  0,  1,  0, 35,  0,  0,  0,  1,  0],\n",
       "       [ 0,  1,  0,  0,  0, 27,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  2,  0, 26,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  2,  1,  0, 27,  0,  2],\n",
       "       [ 0,  5,  4,  1,  1,  0,  3,  0, 28,  1],\n",
       "       [ 0,  1,  1,  2,  2,  1,  0,  0,  0, 25]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0, 42,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 34,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 27,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  1,  0, 27,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 32,  0,  1],\n",
       "       [ 0,  3,  0,  0,  1,  1,  0,  2, 36,  0],\n",
       "       [ 0,  0,  0,  0,  0,  2,  0,  0,  0, 30]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm.SVC() # SVC모델 가져오기\n",
    "\n",
    "\n",
    "\n",
    "svm_model.fit(X_train, y_train) # 모델 훈련 시키기\n",
    "y_pred = svm_model.predict(X_test) # 모델 테스트하기\n",
    "print(classification_report(y_test, y_pred)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 42,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 34,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 28,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 33,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  1,  0,  0, 40,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0, 31]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier 사용해 보기<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.86      0.86      0.86        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.93      0.79      0.86        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.61      1.00      0.76        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.90      0.81      0.85        43\n",
      "           9       0.96      0.72      0.82        32\n",
      "\n",
      "    accuracy                           0.91       360\n",
      "   macro avg       0.92      0.91      0.90       360\n",
      "weighted avg       0.92      0.91      0.91       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier() #sgd_model 가져오기\n",
    "sgd_model.fit(X_train, y_train) # 모델 훈련 시키기\n",
    "y_pred = sgd_model.predict(X_test) # 모델 테스트기기\n",
    "print(classification_report(y_test, y_pred)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 36,  0,  1,  0,  3,  0,  0,  1,  1],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 27,  0,  6,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0, 36,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0, 26,  0,  1,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0, 32,  0,  0],\n",
       "       [ 0,  4,  1,  0,  0,  3,  0,  0, 35,  0],\n",
       "       [ 0,  1,  0,  0,  0,  6,  0,  0,  2, 23]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.84      0.88        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.96      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state = 32, max_iter = 2000)#logistic_model 가져오기\n",
    "#max_iter 해를 찾아가는 데 있어서 반복횟수를 제한한다. 무한루프방지\n",
    "\n",
    "logistic_model.fit(X_train, y_train) # 모델 훈련 시키기\n",
    "y_pred = logistic_model.predict(X_test) # 모델 테스트기기\n",
    "print(classification_report(y_test, y_pred)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오류내용  \n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:   \n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html   \n",
    "Please also refer to the documentation for alternative solver options:   \n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression   \n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)  영\n",
    "  \n",
    "  ## 변경내용\n",
    "  logistic_model = LogisticRegression(random_state = 32, max_iter = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_iter 해를 찾아가는 데 있어서 반복횟수를 제한한다. 무한루프방지  \n",
    "max_iter인자를 추가 하지 않았을때 경고 뜸  \n",
    "https://blog.naver.com/gdpresent/221703566189 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 40,  0,  0,  0,  0,  0,  0,  1,  1],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 33,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 27,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 27,  0,  1,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0, 32,  0,  0],\n",
       "       [ 0,  2,  1,  0,  0,  4,  0,  0, 36,  0],\n",
       "       [ 0,  0,  0,  1,  0,  3,  0,  0,  0, 28]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"font-size:115%; background-color:#eafbee;\" >\n",
    "\n",
    "각 모델에 대한 오차행렬을 봤을때 비중이 거의 TP와 TN로 구성되어 있다.(페이지 상단의 다중클래스오차행렬 사이트참조)  \n",
    "    정밀도 판단에 사용되는 FP, 재현율에 사용되는 FP는 0에 수렴한다.즉 정밀도수식과 재현율수식이 같아진다. 즉 손글씨에서는 정밀도,재현율, f-1 score 는 같은 수식이라고 생각된다. 성능 평가 지표로 어떤것이 적절하다고 하면 f-1 score로 정하겠다.( 이유는 정밀도와 재현율 두 지표를 활용한 값이기 때문에)  \n",
    "또한 support수를 확인하면 각 클래스에 대하여 비슷한 숫자들로 잘 분배가 되어 있기에 accuracy도 평가 지표로 활용되기에 적절하다고 생각된다.\n",
    "\n",
    "5개의 모델의 성능지표를 확인해보면 SVM모델은 모든 면에서 높은 수치를 가지고 있다. 즉 손글씨를 판단할때 SVM모델이 적절하다고 생각된다.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 와인 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 모듈 import하기\n",
    "from sklearn.datasets import load_wine # 사이킷런 토이데이터셋(와인)\n",
    "from sklearn.model_selection import train_test_split # 분리를 위한 패키지\n",
    "from sklearn.metrics import classification_report # 정밀도, 재현율, F1 score 제공하는 패키지\n",
    "\n",
    "#데이터 준비\n",
    "wine = load_wine()\n",
    "wine.keys() #load_wine() 어떤 정보들이 담겼을지, keys() 라는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Data 지정하기\n",
    "wine_data = wine.data\n",
    "wine_data.shape # 178개의 데이터와 13개 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label Data 지정하기\n",
    "wine_label = wine.target\n",
    "#Target Names 출력해 보기\n",
    "wine.target_names # 라벨의 이름을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터 Describe 해 보기\n",
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  142 , X_test 개수:  36\n"
     ]
    }
   ],
   "source": [
    "#train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data,    # 데이터 feature \n",
    "                                                    wine_label,   # 데이터 label  클래스 3개\n",
    "                                                    test_size=0.2,# 전체 개 20%만 테스트 데이터로 사용하겠다.\n",
    "                                                    random_state=7)\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터 178개에서 142개의 훈련데이터, 36개의 테스트데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # 의사결정트리 패키지\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForest 모델\n",
    "from sklearn import svm # svm모델\n",
    "from sklearn.linear_model import SGDClassifier #SGD모델\n",
    "from sklearn.linear_model import LogisticRegression #로지스틱 회귀 모델 \n",
    "from sklearn.metrics import classification_report  # 정확도(precision,recall,f1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0],\n",
       "       [ 0, 17,  0],\n",
       "       [ 0,  2, 10]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0],\n",
       "       [ 0, 17,  0],\n",
       "       [ 0,  0, 12]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm.SVC() # SVC모델 가져오기\n",
    "svm_model.fit(X_train, y_train) # 모델 훈련 시키기\n",
    "y_pred = svm_model.predict(X_test) # 모델 테스트하기\n",
    "print(classification_report(y_test, y_pred)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  0,  1],\n",
       "       [ 1, 15,  1],\n",
       "       [ 0, 11,  1]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83         7\n",
      "           1       0.75      0.71      0.73        17\n",
      "           2       0.53      0.67      0.59        12\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.76      0.70      0.72        36\n",
      "weighted avg       0.73      0.69      0.70        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier() #sgd_model 가져오기\n",
    "\n",
    "\n",
    "\n",
    "sgd_model.fit(X_train, y_train) # 모델 훈련 시키기\n",
    "y_pred = sgd_model.predict(X_test) # 모델 테스트기기\n",
    "y_pred\n",
    "print(classification_report(y_test, y_pred)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경고\n",
    "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.   _warn_prf(average, modifier, msg_start, len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  0,  2],\n",
       "       [ 0, 12,  5],\n",
       "       [ 0,  4,  8]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state = 32, max_iter = 4000)#logistic_model 가져오기\n",
    "#max_iter 해를 찾아가는 데 있어서 반복횟수를 제한한다. 무한루프방지\n",
    "\n",
    "logistic_model.fit(X_train, y_train) # 모델 훈련 시키기\n",
    "y_pred = logistic_model.predict(X_test) # 모델 테스트기기\n",
    "print(classification_report(y_test, y_pred)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_iter 해를 찾아가는 데 있어서 반복횟수를 제한한다. 무한루프방지  \n",
    "max_iter인자를 추가 하지 않았을때 경고 뜸  \n",
    "https://blog.naver.com/gdpresent/221703566189 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0],\n",
       "       [ 0, 17,  0],\n",
       "       [ 0,  1, 11]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와인은 178개 이미지, 13개 특징, 3개의 클래스   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:115%; background-color:#eafbee;\" >\n",
    "각 모델에 대한 오차행렬을 봤을때 SVM와 SGD 빼고 3개의 모델의 성능지표 비중이 거의 TP와 TN로 구성되어 있다.즉 손글씨를 판단했을때 처럼 F1 socre를 성능지표로 평가 하기 좋을것같다. SVM와 SGD를 오차행렬로 깊숙하게 들어갈수도 있으나, \"𝐹𝑃와 𝐹𝑁 값이 꽤 있어 정밀도와, 재현율의 값이 낮구나\"라고 이해하겠다.(다중 오차행렬 이해하기 어렵다...)    \n",
    "    \n",
    "모델중 Logistic Regression,Random Forest,Decision Tree 는 95%이상,Logistic Regression,Random Forest 는 저조한 성능지표를 보여준다.특히 Random Forest의 각각의 precision,recall,f1-score, accuracy가 1로 가장 높은 값을 가진다. 그래서 모델로써는 Random Forest가 적절하다고 생각된다.    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유방암"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 모듈 import하기\n",
    "from sklearn.datasets import load_breast_cancer # 사이킷런 토이데이터셋(유방암)\n",
    "from sklearn.model_selection import train_test_split # 분리를 위한 패키지\n",
    "from sklearn.metrics import classification_report # 정밀도, 재현율, F1 score 제공하는 패키지\n",
    "\n",
    "#데이터 준비\n",
    "breast_cancer = load_breast_cancer()\n",
    "breast_cancer.keys() #breast_cancer.key() 어떤 정보들이 담겼을지, keys() 라는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Data 지정하기\n",
    "breast_cancer_data = breast_cancer.data\n",
    "breast_cancer_data.shape # 569개의 데이터와 30개 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label Data 지정하기\n",
    "breast_cancer_label = breast_cancer.target\n",
    "#Target Names 출력해 보기\n",
    "breast_cancer.target_names # 라벨의 이름을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "#데이터 Describe 해 보기\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  455 , X_test 개수:  114\n"
     ]
    }
   ],
   "source": [
    "#train, test 데이터 분리\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data,    # 데이터 feature \n",
    "                                                    breast_cancer_label,   # 데이터 label   ['malignant', 'benign'] 2개\n",
    "                                                    test_size=0.2,# 전체 중 20%만 테스트 데이터로 사용하겠다.\n",
    "                                                    random_state=7)\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터 569개에서 455개의 훈련데이터, 114개의 테스트데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.tree import DecisionTreeClassifier # 의사결정트리 패키지\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForest 모델\n",
    "from sklearn import svm # svm모델\n",
    "from sklearn.linear_model import SGDClassifier #SGD모델\n",
    "from sklearn.linear_model import LogisticRegression #로지스틱 회귀 모델 \n",
    "from sklearn.metrics import classification_report  # 정확도(precision,recall,f1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  7],\n",
       "       [ 3, 71]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 사용해 보기 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm.SVC() # SVC모델 가져오기\n",
    "svm_model.fit(X_train, y_train) # 모델 훈련 시키기\n",
    "y_pred = svm_model.predict(X_test) # 모델 테스트하기\n",
    "print(classification_report(y_test, y_pred)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29, 11],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier 사용해 보기<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84        40\n",
      "           1       0.89      0.96      0.92        74\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.90      0.87      0.88       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier() #sgd_model 가져오기\n",
    "sgd_model.fit(X_train, y_train) # 모델 훈련 시키기\n",
    "y_pred = sgd_model.predict(X_test) # 모델 테스트기기\n",
    "print(classification_report(y_test, y_pred)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31,  9],\n",
       "       [ 3, 71]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state = 32, max_iter = 4000)#logistic_model 가져오기\n",
    "#max_iter 해를 찾아가는 데 있어서 반복횟수를 제한한다. 무한루프방지\n",
    "\n",
    "logistic_model.fit(X_train, y_train) # 모델 훈련 시키기\n",
    "y_pred = logistic_model.predict(X_test) # 모델 테스트기기\n",
    "print(classification_report(y_test, y_pred)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_iter 해를 찾아가는 데 있어서 반복횟수를 제한한다. 무한루프방지  \n",
    "max_iter인자를 추가 하지 않았을때 경고 뜸  \n",
    "https://blog.naver.com/gdpresent/221703566189 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34,  6],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "malignant, benign 설명  \n",
    "https://www.doctorsnews.co.kr/news/articleView.html?idxno=20924&sc_word=&sc_word2="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:115%; background-color:#eafbee;\" >\n",
    "암을 판단하는 경우 정밀도(TP,FP)보다는 재현율(TP,FN)에 더욱 집중적으로 봐야된다.왜냐하면 양성인사람에게 음성예측할 경우 치명적이기 때문이다.  \n",
    "\n",
    "유방암 class는 2가지가 있는데 'malignant'와 'benign'이다. malignant는 암이라고 하고,benign는 전이하지 않는 종양이라고 이해하겠다.  \n",
    "malignant = class0,  benign=class1  \n",
    "class0은 종양을 암을 판단하는기준, class1는 종양을 암이 아닌것으로 판단하는 기준이기 때문에 class0은 recall 지표가 중요하고, class1은 precision 중요하다.    \n",
    "  \n",
    "유방암 모델을 선별함에 있어서 성능지표를 살펴보았는데 Random Forest모델이  precision, recall, f1-score 1,accracy가 1로 나왔다. 다른 모델에 월등했다. 즉 유방암판단 모델로써는 Random Forest 적절하다고 생각된다.\n",
    "    \n",
    "\n",
    "</div>\n",
    "그런데 SGD Classifier 모델의 성능 지표값은 계속 변경된다. 왜 그런지 찾아보았지만 결론을 도출하지 못하였다. 추후 노드를 진행하면서 천천히 이해하기로 했다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "1.오차행렬로 성능지표를 판단하는구나?   \n",
    "2 오차행렬 예측 결과(TP, TN, FP, FF) 이해가 되지가 않는구나...  \n",
    "3.오차행렬로 정밀도,재현율,정확도,fi score 파악하기  \n",
    "4.오차행렬이 2x2행령으로만 표현되는것이 아니구나( 다중오차행렬 )   \n",
    "5.모델에 하나에 대한 성능지표값이 있는것이 아니구나(모델의 클래스/라벨에 대한 각각의 정밀도,재현율,정확도,f1 score 존재)   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차 행렬에서 TN,TP,FP,FN 개념이 이해하는데 어려움이 있었다. (말싸움하는 것 같다) 또한 노드에는 이진 오차 행렬을 설명해주고 있어서 '모든 모델은 2진 오차 행렬만 갖겠구나?' 하는 착각에 빠졌는데, 다행히 슬랙에서 다른 교육생분의 다중 오차 행렬에 대한 사이트를 제공해주셔서 이해하는 데 도움이 됐다. 모델 5개에 대한 훈련과 성능지표를 확인하면서 왜 이 모델은 이렇게 나오고, 저렇게 나오지? 라는 의문이 들었는데 이것 추후 진도를 나간다면 답을 찾을 수 있을 것이라고 생각해야겠다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
